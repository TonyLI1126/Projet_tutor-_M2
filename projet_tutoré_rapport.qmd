---
title: "PROJET TUTORE M2"
format: html
editor: visual
author: Tony LI - Saïd BENAISSA
---

# Projet tutoré : Mouvement brownien, ANOVA, phylogénie...

## L'arbre phylogénétique

Nous considérons un arbre phylogénétique représentant les relations évolutives entre quatre feuilles issues d’un ancêtre commun A0.

```{r}
library(ape)
library(phytools)
library(dplyr)
library(purrr)
library(ggplot2)


n_tips = 5  # nombre d'espèces terminales
lambda = 1   # taux de spéciation (naissance)
mu = 0       # taux d'extinction (0 = pur birth)

tree= rphylo(n = n_tips, birth = lambda, death = mu)
plot(tree, show.tip.label = TRUE, cex = 0.9, main = "Arbre simulé avec rphylo()")
edgelabels()
nodelabels()
tiplabels()
```

```{r}
simulate_bm <- function(t_e, N) {
  # 1. choose a regular grid on [0,T] with step dt = t_e / N
  dt <- t_e / N
  time <- seq(0, t_e, dt)
  # 2. define data frame and set W_0 = 0
  traj <- data.frame(time = time, value = rep(NA, N+1))
  traj$value[1] <- 0
  # 3. simulate increments dW_n ~ N(0, dt) for 1 <= n <= N
  dW <- rep(NA, N)
  for (n in 1:N) {
    dW[n] <- rnorm(1, mean = 0, sd = sqrt(dt))
  }
  # 4. write W_n = \sum_{i=1}^n dW_i for 1 <= n <= N in the dataframe
  traj$value[-1] <- cumsum(dW)
  # return dataframe
  return(traj)
}
```

```{r}
## choose a time step
dt <- 0.001
## choose starting value
mu <- 1.3
## Create a data frame with the simulated trajectory
dftree <- data.frame(value = numeric(0),       # position of the BM
                     time = numeric(0),        # time elapsed since root
                     edge = numeric(0))        # number of the edge of the tree
## traverse the tree from edge to edge
for (i in 1:nrow(tree$edge)) {
  # simulate a BM starting at (0,0) on the current branch
  t_branch <- tree$edge.length[i]
  N_branch <- floor(t_branch / dt)
  current_BM <- simulate_bm(t_branch, N_branch)
  # find the parent edge of the starting node of the current edge
  parent_edge <- which(tree$edge[i, 1] == tree$edge[, 2])
  # case where current edge does not a parent edge
  if (length(parent_edge) == 0) {
    # add starting value mu
    current_BM$value <- current_BM$value + mu
  } else { # case where current edge do have a parent edge
    # find last value on the parent branch
    dfparent <- dftree[dftree$edge == parent_edge, ]
    last_parent <- dfparent[nrow(dfparent), ]
    # add last value of parent as starting value of the branch
    current_BM$value <- current_BM$value + last_parent$value
    current_BM$time <- current_BM$time + last_parent$time
  }
  # fill in the dataframe
  dfbranch <-  data.frame(value = current_BM$value,
                          time = current_BM$time,
                          edge = i)
  # update dftree
  dftree <- rbind(dftree, dfbranch)
}
```

```{r}
p <- ggplot(dftree, aes(time, value, color = as.factor(edge))) +
  geom_path(linewidth = 1)
p
```

On peut décrire l’évolution d’un caractère quantitatif **T** (par ex. la taille d’une feuille) par un mouvement brownien au cours du temps évolutif **t** (dans le cas de la phylogénie).

Mouvement brownien appliqué à l'évolution d'un caractère continu le long d'un arbre phylogénétique

Le mouvement brownien est un processus stochastique fondamental servant de modèle pour décrire l’évolution aléatoire d’un caractère continu au cours du temps. Il s’agit du processus le plus simple vérifiant les propriétés suivantes : - il est **continu** presque sûrement ; - il possède des accroissements indépendants et stationnaires ; - chaque accroissement est gaussien de moyenne nulle.

On appelle mouvement brownien standard $((B_t)_{t \ge 0})$ le processus stochastique tel que :

\begin{cases}
B_0 = 0,\\[4pt]
B_t - B_s \sim \mathcal{N}(0, t-s), \quad \text{pour } 0 \le s < t,\\[4pt]
\text{les accroissements sont indépendants.}
\end{cases}

## Covariance sous mouvement brownien sur un arbre

On considère un arbre enraciné, où chaque feuille $i$ est reliée à la racine par un chemin de longueur $t_i$.\
Pour deux feuilles $i$ et $j$, on note $t_{ij}$ la longueur du chemin commun depuis la racine jusqu’au MRCA (dernier ancêtre commun).

Le caractère évolue le long de l’arbre selon un mouvement brownien, avec valeur moyenne $\mu$ à la racine.

Modèle utilisé:

On note la valeur du caractère au MRCA de $i$ et $j$ par $Z_{ij}$, alors :

$$
Z_{ij} \sim \mathcal{N}(\mu,\; \sigma^2 t_{ij})
$$

et les valeurs terminales $Y_i$ et $Y_j$ s’écrivent :

$$
Y_i \mid Z_{ij} \sim \mathcal{N}(Z_{ij},\; \sigma^2 (t_i - t_{ij}))
$$

$$
Y_j \mid Z_{ij} \sim \mathcal{N}(Z_{ij},\; \sigma^2 (t_j - t_{ij}))
$$

Autrement dit, on peut écrire :

$$
Y_i = Z_{ij} + \varepsilon_i, \quad \varepsilon_i \sim \mathcal{N}(0,\; \sigma^2 (t_i - t_{ij}))
$$

$$
Y_j = Z_{ij} + \varepsilon_j, \quad \varepsilon_j \sim \mathcal{N}(0,\; \sigma^2 (t_j - t_{ij}))
$$Indépendance des composantes:

Le mouvement brownien nous assure que :

\- $Z_{ij}$ dépend uniquement de l’évolution du caractère sur les branches commune (jusqu’au MRCA),\
- $\varepsilon_i$ dépend des accroissements après la séparation, sur la branche propre à $i$,\
- $\varepsilon_j$ dépend des accroissements après la séparation, sur la branche propre à $j$.

Comme ces ensembles de branches sont disjoints, on a :

$$
Z_{ij} \perp \varepsilon_i, \quad Z_{ij} \perp \varepsilon_j, \quad \varepsilon_i \perp \varepsilon_j
$$Calcul de la covariance:

On développe : $$
\operatorname{Cov}(Y_i, Y_j)
= \operatorname{Cov}(Z_{ij} + \varepsilon_i,\; Z_{ij} + \varepsilon_j)
$$

Par bilinéarité de la covariance : $$
\operatorname{Cov}(Y_i, Y_j)
= \operatorname{Cov}(Z_{ij}, Z_{ij})
+ \operatorname{Cov}(Z_{ij}, \varepsilon_j)
+ \operatorname{Cov}(\varepsilon_i, Z_{ij})
+ \operatorname{Cov}(\varepsilon_i, \varepsilon_j)
$$

Les trois derniers termes sont nuls par indépendance (vu en haut): $$
\operatorname{Cov}(Z_{ij}, \varepsilon_j)
= \operatorname{Cov}(\varepsilon_i, Z_{ij})
= \operatorname{Cov}(\varepsilon_i, \varepsilon_j)
= 0.
$$

Il reste donc : $$
\operatorname{Cov}(Y_i, Y_j)
= \operatorname{Var}(Z_{ij})
= \sigma^2 t_{ij}.
$$Conclusion

$$
\operatorname{Cov}(Y_i, Y_j) = \sigma^2\, t_{ij}
$$

Etape suivante formule beta etc

## Estimation de $\beta$ dans la régression phylogénétique

On considère le modèle linéaire :

$$
Y = X\beta + \sigma \varepsilon, 
\qquad \varepsilon \sim \mathcal N(0,\,C)
$$

où $Y$ est le vecteur des observations, $X$ la matrice de design, $\beta$ le vecteur de paramètres, et $C$ la matrice de covariance phylogénétique.

### Cas classique : erreurs indépendantes

Si $\varepsilon \sim \mathcal N(0, I)$, alors l'estimation par moindres carrés consiste à minimiser:

$$
Q(\beta)=\|Y - X\beta\|^2
= (Y - X\beta)^\top (Y - X\beta).
$$

On développe terme à terme:

$$
Q(\beta) = Y^\top Y - 2\beta^\top X^\top Y + \beta^\top X^\top X\,\beta.
$$

On dérive par rapport à $\beta$ :

$$
\frac{\partial Q}{\partial \beta}
= -2X^\top Y + 2X^\top X\,\beta.
$$

En annulant l'équation, on obtient :

$$
X^\top (Y - X\hat\beta) = 0
\quad \Longrightarrow \quad
X^\top X\,\hat\beta = X^\top Y.
$$

Donc l'estimateur dans le cas classique est :

$$
\hat\beta_{\text{OLS}} = (X^\top X)^{-1} X^\top Y.
$$

### Cas phylogénétique : erreurs corrélées

Maintenant, les erreurs suivent $\varepsilon \sim \mathcal N(0,\,C)$, donc les observations sont corrélées mais on connait $C$ grâce à l'arbre, qui est la covariance phylogénétique sous MB.

On utilise la décomposition de Cholesky :

$$
C = LL^\top.
$$

On remplace et réécrit en fonction des $L$ :

$$
\tilde Y = L^{-1}Y, 
\qquad 
\tilde X = L^{-1}X, 
\qquad 
\tilde\varepsilon = L^{-1}\varepsilon.
$$

Alors:

$$
\tilde Y = \tilde X\beta + \sigma\tilde\varepsilon,
\qquad
\tilde\varepsilon \sim \mathcal N(0, I).
$$

On a donc un modèle linéaire classique sur les données transformées et on peut appliquer les mêmes méthodes que dans le cas classiques.

#### Estimateurs de $\beta$ dans le cas phylogénétique

On minimise:

$$
\tilde Q(\beta)
=\|\tilde Y - \tilde X\beta\|^2
=(\tilde Y - \tilde X\beta)^\top(\tilde Y - \tilde X\beta).
$$

On développe terme à terme:

$$
\tilde Q(\beta)
= \tilde Y^\top \tilde Y
- 2\,\beta^\top \tilde X^\top \tilde Y
+ \beta^\top \tilde X^\top \tilde X\,\beta.
$$

On dérive par rapport à $\beta$ :

$$
\frac{\partial \tilde Q}{\partial \beta}
= -2\,\tilde X^\top \tilde Y + 2\,\tilde X^\top \tilde X\,\beta.
$$

On cherche à annuler cette équation et on trouve la forme:

$$
\tilde X^\top \tilde X\,\hat\beta
= \tilde X^\top \tilde Y.
$$

Donc en isolant $\beta$ :

$$
\hat\beta
= (\tilde X^\top \tilde X)^{-1} \tilde X^\top \tilde Y.
$$

Avec $\tilde X = L^{-1}X$ et $\tilde Y = L^{-1}Y$ , on remplace:

$$
\tilde X^\top \tilde X
= X^\top (L^{-1})^\top L^{-1} X
= X^\top C^{-1} X,
\qquad
\tilde X^\top \tilde Y
= X^\top (L^{-1})^\top L^{-1} Y
= X^\top C^{-1} Y,
$$

puisque $(L^{-1})^\top L^{-1}=(LL^\top)^{-1}=C^{-1}$ :

On a finalement:

$$
\boxed{
\hat\beta = (X^\top C^{-1}X)^{-1} X^\top C^{-1}Y
}
$$

On a l'estimateur de $\beta$ qui est celui des moindres carrés généralisés

## Estimation de $\sigma^2$ dans la régression phylogénétique

On considère le modèle linéaire :

$$
Y = X\beta + \sigma \varepsilon, \qquad \varepsilon \sim \mathcal N(0,\,C)
$$

où $Y$ est le vecteur des observations, $X$ la matrice de design, $\beta$ le vecteur de paramètres, et $C$ la matrice de covariance phylogénétique.

### Cas classique : erreurs indépendantes

Dans le cas $\varepsilon \sim \mathcal N(0,I)$, on définit le résidu:

$$
\hat r = Y - X\hat\beta_{\text{OLS}},
\qquad \hat\beta_{\text{OLS}} = (X^\top X)^{-1}X^\top Y.
$$

L’estimateur non biaisé de $\sigma^2$ est :

$$
\boxed{\ \hat\sigma^2_{\text{OLS}}
= \frac{1}{n-p}\,\|Y - X\hat\beta_{\text{OLS}}\|^2
= \frac{1}{n-p}\,(Y-X\hat\beta_{\text{OLS}})^\top (Y-X\hat\beta_{\text{OLS}})\ }.
$$

### Cas phylogénétique : erreurs corrélées

Ici $\varepsilon \sim \mathcal N(0,C)$.\
On note la décomposition de Cholesky :

$$
C = LL^\top.
$$

Comme pour l'estimation de $\beta$ on a donc :

$$
\tilde Y = L^{-1}Y, \qquad \tilde X = L^{-1}X, \qquad \tilde\varepsilon = L^{-1}\varepsilon \sim \mathcal N(0,I).
$$

Le modèle devient donc:

$$
\tilde Y = \tilde X\beta + \sigma\tilde\varepsilon.
$$

et l'estimateur de $\beta$ GLS devient:

$$
\hat\beta = (X^\top C^{-1}X)^{-1}X^\top C^{-1}Y.
$$

On définit les résidus :

$$
\hat r = Y - X\hat\beta, 
\qquad 
\tilde r = \tilde Y - \tilde X \hat\beta = L^{-1}\hat r.
$$

Alors :

$$
\hat\sigma^2
= \frac{1}{n-p}\|\tilde r\|^2
= \frac{1}{n-p}\,(\tilde Y - \tilde X\hat\beta)^\top(\tilde Y - \tilde X\hat\beta).
$$

En remplaçant $\tilde r = L^{-1}\hat r$ :

$$
\begin{aligned}
\|\tilde r\|^2
&= (L^{-1}\hat r)^\top(L^{-1}\hat r) \\
&= \hat r^\top (L^{-1})^\top L^{-1} \hat r \\
&= \hat r^\top (LL^\top)^{-1} \hat r \\
&= \hat r^\top C^{-1} \hat r
= (Y - X\hat\beta)^\top C^{-1}(Y - X\hat\beta).
\end{aligned}
$$

et au final on a :

$$
\boxed{
\hat\sigma^2
= \frac{1}{n-p}(Y - X\hat\beta)^\top C^{-1}(Y - X\hat\beta)
= \frac{1}{n-p}\|\tilde Y - \tilde X\hat\beta\|^2
}.
$$
